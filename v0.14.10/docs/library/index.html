<p><a id="Index"></a></p>

<p><a id="Index-1"></a></p>

<h2 id="index">Index</h2>

<ul>
  <li><a href="/v0.14/docs/library/#Turing.BinomialLogit"><code class="language-plaintext highlighter-rouge">Turing.BinomialLogit</code></a></li>
  <li><a href="/v0.14/docs/library/#Turing.Flat"><code class="language-plaintext highlighter-rouge">Turing.Flat</code></a></li>
  <li><a href="/v0.14/docs/library/#Turing.FlatPos"><code class="language-plaintext highlighter-rouge">Turing.FlatPos</code></a></li>
  <li><a href="/v0.14/docs/library/#Turing.OrderedLogistic"><code class="language-plaintext highlighter-rouge">Turing.OrderedLogistic</code></a></li>
  <li><a href="/v0.14/docs/library/#Turing.Inference.Gibbs"><code class="language-plaintext highlighter-rouge">Turing.Inference.Gibbs</code></a></li>
  <li><a href="/v0.14/docs/library/#Turing.Inference.HMC"><code class="language-plaintext highlighter-rouge">Turing.Inference.HMC</code></a></li>
  <li><a href="/v0.14/docs/library/#Turing.Inference.HMCDA"><code class="language-plaintext highlighter-rouge">Turing.Inference.HMCDA</code></a></li>
  <li><a href="/v0.14/docs/library/#Turing.Inference.IS"><code class="language-plaintext highlighter-rouge">Turing.Inference.IS</code></a></li>
  <li><a href="/v0.14/docs/library/#Turing.Inference.MH"><code class="language-plaintext highlighter-rouge">Turing.Inference.MH</code></a></li>
  <li><a href="/v0.14/docs/library/#Turing.Inference.NUTS"><code class="language-plaintext highlighter-rouge">Turing.Inference.NUTS</code></a></li>
  <li><a href="/v0.14/docs/library/#Turing.Inference.PG"><code class="language-plaintext highlighter-rouge">Turing.Inference.PG</code></a></li>
  <li><a href="/v0.14/docs/library/#Turing.Inference.SMC"><code class="language-plaintext highlighter-rouge">Turing.Inference.SMC</code></a></li>
  <li><a href="/v0.14/docs/library/#Libtask.TArray"><code class="language-plaintext highlighter-rouge">Libtask.TArray</code></a></li>
  <li><a href="/v0.14/docs/library/#Libtask.tzeros"><code class="language-plaintext highlighter-rouge">Libtask.tzeros</code></a></li>
</ul>

<p><a id="Modelling"></a></p>

<p><a id="Modelling-1"></a></p>

<h2 id="modelling">Modelling</h2>

<h3 id="-dynamicpplmodel--macro"><a id="DynamicPPL.@model" href="#DynamicPPL.@model">#</a> <strong><code class="language-plaintext highlighter-rouge">DynamicPPL.@model</code></strong> — <em>Macro</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span><span class="x">(</span><span class="n">expr</span><span class="x">[,</span> <span class="n">warn</span> <span class="o">=</span> <span class="nb">true</span><span class="x">])</span>
</code></pre></div></div>

<p>Macro to specify a probabilistic model.</p>

<p>If <code class="language-plaintext highlighter-rouge">warn</code> is <code class="language-plaintext highlighter-rouge">true</code>, a warning is displayed if internal variable names are used in the model definition.</p>

<p><strong>Examples</strong></p>

<p>Model definition:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> model</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mi">42</span><span class="x">)</span>
    <span class="o">...</span>
<span class="k">end</span>
</code></pre></div></div>

<p>To generate a <code class="language-plaintext highlighter-rouge">Model</code>, call <code class="language-plaintext highlighter-rouge">model(xvalue)</code> or <code class="language-plaintext highlighter-rouge">model(xvalue, yvalue)</code>.</p>

<p><a id="Samplers"></a></p>

<p><a id="Samplers-1"></a></p>

<h2 id="samplers">Samplers</h2>

<h3 id="-dynamicpplsampler--type"><a id="DynamicPPL.Sampler" href="#DynamicPPL.Sampler">#</a> <strong><code class="language-plaintext highlighter-rouge">DynamicPPL.Sampler</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Sampler</span><span class="x">{</span><span class="n">T</span><span class="x">}</span>
</code></pre></div></div>

<p>Generic interface for implementing inference algorithms. An implementation of an algorithm should include the following:</p>

<ol>
  <li>A type specifying the algorithm and its parameters, derived from InferenceAlgorithm</li>
  <li>A method of <code class="language-plaintext highlighter-rouge">sample</code> function that produces results of inference, which is where actual inference happens.</li>
</ol>

<p>DynamicPPL translates models to chunks that call the modelling functions at specified points. The dispatch is based on the value of a <code class="language-plaintext highlighter-rouge">sampler</code> variable. To include a new inference algorithm implements the requirements mentioned above in a separate file, then include that file at the end of this one.</p>

<h3 id="-turinginferencegibbs--type"><a id="Turing.Inference.Gibbs" href="#Turing.Inference.Gibbs">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.Inference.Gibbs</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Gibbs</span><span class="x">(</span><span class="n">algs</span><span class="o">...</span><span class="x">)</span>
</code></pre></div></div>

<p>Compositional MCMC interface. Gibbs sampling combines one or more sampling algorithms, each of which samples from a different set of variables in a model.</p>

<p>Example:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="n">gibbs_example</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
    <span class="n">v1</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="mi">1</span><span class="x">)</span>
    <span class="n">v2</span> <span class="o">~</span> <span class="n">Categorical</span><span class="x">(</span><span class="mi">5</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p><strong>Use PG for a ‘v2’ variable, and use HMC for the ‘v1’ variable.</strong></p>

<p><strong>Note that v2 is discrete, so the PG sampler is more appropriate</strong></p>

<p><strong>than is HMC.</strong></p>

<p>alg = Gibbs(HMC(0.2, 3, :v1), PG(20, :v2)) ```</p>

<p>Tips:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">HMC</code> and <code class="language-plaintext highlighter-rouge">NUTS</code> are fast samplers, and can throw off particle-based</li>
</ul>

<p>methods like Particle Gibbs. You can increase the effectiveness of particle sampling by including more particles in the particle sampler.</p>

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/inference/gibbs.jl#L14-L39" class="documenter-source">source</a><br /></p>

<h3 id="-turinginferencehmc--type"><a id="Turing.Inference.HMC" href="#Turing.Inference.HMC">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.Inference.HMC</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">HMC</span><span class="x">(</span><span class="n">ϵ</span><span class="o">::</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">n_leapfrog</span><span class="o">::</span><span class="kt">Int</span><span class="x">)</span>
</code></pre></div></div>

<p>Hamiltonian Monte Carlo sampler with static trajectory.</p>

<p>Arguments:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">ϵ::Float64</code> : The leapfrog step size to use.</li>
  <li><code class="language-plaintext highlighter-rouge">n_leapfrog::Int</code> : The number of leapfrop steps to use.</li>
</ul>

<p>Usage:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">HMC</span><span class="x">(</span><span class="mf">0.05</span><span class="x">,</span> <span class="mi">10</span><span class="x">)</span>
</code></pre></div></div>

<p>Tips:</p>

<ul>
  <li>If you are receiving gradient errors when using <code class="language-plaintext highlighter-rouge">HMC</code>, try reducing the leapfrog step size <code class="language-plaintext highlighter-rouge">ϵ</code>, e.g.</li>
</ul>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Original step size</span>
<span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">([</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">]),</span> <span class="n">HMC</span><span class="x">(</span><span class="mf">0.1</span><span class="x">,</span> <span class="mi">10</span><span class="x">),</span> <span class="mi">1000</span><span class="x">)</span>

<span class="c"># Reduced step size</span>
<span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">([</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">]),</span> <span class="n">HMC</span><span class="x">(</span><span class="mf">0.01</span><span class="x">,</span> <span class="mi">10</span><span class="x">),</span> <span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/inference/hmc.jl#L46-L73" class="documenter-source">source</a><br /></p>

<h3 id="-turinginferencehmcda--type"><a id="Turing.Inference.HMCDA" href="#Turing.Inference.HMCDA">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.Inference.HMCDA</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">HMCDA</span><span class="x">(</span><span class="n">n_adapts</span><span class="o">::</span><span class="kt">Int</span><span class="x">,</span> <span class="n">δ</span><span class="o">::</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">λ</span><span class="o">::</span><span class="kt">Float64</span><span class="x">;</span> <span class="n">ϵ</span><span class="o">::</span><span class="kt">Float64</span><span class="o">=</span><span class="mf">0.0</span><span class="x">)</span>
</code></pre></div></div>

<p>Hamiltonian Monte Carlo sampler with Dual Averaging algorithm.</p>

<p>Usage:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">HMCDA</span><span class="x">(</span><span class="mi">200</span><span class="x">,</span> <span class="mf">0.65</span><span class="x">,</span> <span class="mf">0.3</span><span class="x">)</span>
</code></pre></div></div>

<p>Arguments:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">n_adapts::Int</code> : Numbers of samples to use for adaptation.</li>
  <li><code class="language-plaintext highlighter-rouge">δ::Float64</code> : Target acceptance rate. 65% is often recommended.</li>
  <li><code class="language-plaintext highlighter-rouge">λ::Float64</code> : Target leapfrop length.</li>
  <li><code class="language-plaintext highlighter-rouge">ϵ::Float64=0.0</code> : Inital step size; 0 means automatically search by Turing.</li>
</ul>

<p>For more information, please view the following paper (<a href="https://arxiv.org/abs/1111.4246">arXiv link</a>):</p>

<ul>
  <li>Hoffman, Matthew D., and Andrew Gelman. “The No-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.” Journal of Machine Learning Research 15, no. 1 (2014): 1593-1623.</li>
</ul>

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/inference/hmc.jl#L218-L241" class="documenter-source">source</a><br /></p>

<h3 id="-turinginferenceis--type"><a id="Turing.Inference.IS" href="#Turing.Inference.IS">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.Inference.IS</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">IS</span><span class="x">()</span>
</code></pre></div></div>

<p>Importance sampling algorithm.</p>

<p>Note that this method is particle-based, and arrays of variables must be stored in a <a href="/v0.14/docs/library/#Libtask.TArray"><code class="language-plaintext highlighter-rouge">TArray</code></a> object.</p>

<p>Usage:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">IS</span><span class="x">()</span>
</code></pre></div></div>

<p>Example:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Define a simple Normal model with unknown mean and variance.</span>
<span class="nd">@model</span> <span class="n">gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">=</span> <span class="k">begin</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span><span class="n">sqrt</span><span class="o">.</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">x</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="o">.</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">x</span><span class="x">[</span><span class="mi">2</span><span class="x">]</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="o">.</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="k">return</span> <span class="n">s</span><span class="x">,</span> <span class="n">m</span>
<span class="k">end</span>

<span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">([</span><span class="mf">1.5</span><span class="x">,</span> <span class="mi">2</span><span class="x">]),</span> <span class="n">IS</span><span class="x">(),</span> <span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/inference/is.jl#L1-L29" class="documenter-source">source</a><br /></p>

<h3 id="-turinginferencemh--type"><a id="Turing.Inference.MH" href="#Turing.Inference.MH">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.Inference.MH</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MH</span><span class="x">(</span><span class="n">space</span><span class="o">...</span><span class="x">)</span>
</code></pre></div></div>

<p>Construct a Metropolis-Hastings algorithm.</p>

<p>The arguments <code class="language-plaintext highlighter-rouge">space</code> can be</p>

<ul>
  <li>Blank (i.e. <code class="language-plaintext highlighter-rouge">MH()</code>), in which case <code class="language-plaintext highlighter-rouge">MH</code> defaults to using the prior for each parameter as the proposal distribution.</li>
  <li>A set of one or more symbols to sample with <code class="language-plaintext highlighter-rouge">MH</code> in conjunction with <code class="language-plaintext highlighter-rouge">Gibbs</code>, i.e. <code class="language-plaintext highlighter-rouge">Gibbs(MH(:m), PG(10, :s))</code></li>
  <li>An iterable of pairs or tuples mapping a <code class="language-plaintext highlighter-rouge">Symbol</code> to a <code class="language-plaintext highlighter-rouge">AdvancedMH.Proposal</code>, <code class="language-plaintext highlighter-rouge">Distribution</code>, or <code class="language-plaintext highlighter-rouge">Function</code>  that generates returns a conditional proposal distribution.</li>
  <li>A covariance matrix to use as for mean-zero multivariate normal proposals.</li>
</ul>

<p><strong>Examples</strong></p>

<p>The default <code class="language-plaintext highlighter-rouge">MH</code> will use propose samples from the prior distribution using <code class="language-plaintext highlighter-rouge">AdvancedMH.StaticProposal</code>.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">)</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
<span class="k">end</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">),</span> <span class="n">MH</span><span class="x">(),</span> <span class="mi">1_000</span><span class="x">)</span>
<span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">)</span>
</code></pre></div></div>

<p>Alternatively, you can specify particular parameters to sample if you want to combine sampling from multiple samplers:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">)</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
<span class="k">end</span>

<span class="c"># Samples s with MH and m with PG</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span><span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">),</span> <span class="n">Gibbs</span><span class="x">(</span><span class="n">MH</span><span class="x">(</span><span class="o">:</span><span class="n">s</span><span class="x">),</span> <span class="n">PG</span><span class="x">(</span><span class="mi">10</span><span class="x">,</span> <span class="o">:</span><span class="n">m</span><span class="x">)),</span> <span class="mi">1_000</span><span class="x">)</span>
<span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">)</span>
</code></pre></div></div>

<p>Using custom distributions defaults to using static MH:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">)</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
<span class="k">end</span>

<span class="c"># Use a static proposal for s and random walk with proposal </span>
<span class="c"># standard deviation of 0.25 for m.</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span>
    <span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">),</span> 
    <span class="n">MH</span><span class="x">(</span>
        <span class="o">:</span><span class="n">s</span> <span class="o">=&gt;</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">),</span>
        <span class="o">:</span><span class="n">m</span> <span class="o">=&gt;</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
    <span class="x">),</span> 
    <span class="mi">1_000</span>
<span class="x">)</span>
<span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">)</span>
</code></pre></div></div>

<p>Specifying explicit proposals using the <code class="language-plaintext highlighter-rouge">AdvancedMH</code> interface:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">)</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
<span class="k">end</span>

<span class="c"># Use a static proposal for s and random walk with proposal </span>
<span class="c"># standard deviation of 0.25 for m.</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span>
    <span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">),</span> 
    <span class="n">MH</span><span class="x">(</span>
        <span class="o">:</span><span class="n">s</span> <span class="o">=&gt;</span> <span class="n">AdvancedMH</span><span class="o">.</span><span class="n">StaticProposal</span><span class="x">(</span><span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)),</span>
        <span class="o">:</span><span class="n">m</span> <span class="o">=&gt;</span> <span class="n">AdvancedMH</span><span class="o">.</span><span class="n">RandomWalkProposal</span><span class="x">(</span><span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mf">0.25</span><span class="x">))</span>
    <span class="x">),</span> 
    <span class="mi">1_000</span>
<span class="x">)</span>
<span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">)</span>
</code></pre></div></div>

<p>Using a custom function to specify a conditional distribution:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">)</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
<span class="k">end</span>

<span class="c"># Use a static proposal for s and and a conditional proposal for m,</span>
<span class="c"># where the proposal is centered around the current sample.</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span>
    <span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">),</span> 
    <span class="n">MH</span><span class="x">(</span>
        <span class="o">:</span><span class="n">s</span> <span class="o">=&gt;</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span> <span class="mi">3</span><span class="x">),</span>
        <span class="o">:</span><span class="n">m</span> <span class="o">=&gt;</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">Normal</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
    <span class="x">),</span> 
    <span class="mi">1_000</span>
<span class="x">)</span>
<span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">)</span>
</code></pre></div></div>

<p>Providing a covariance matrix will cause <code class="language-plaintext highlighter-rouge">MH</code> to perform random-walk sampling in the transformed space with proposals drawn from a multivariate normal distribution. The provided matrix must be positive semi-definite and square. Usage:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@model</span> <span class="k">function</span><span class="nf"> gdemo</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="n">y</span><span class="x">)</span>
    <span class="n">s</span> <span class="o">~</span> <span class="n">InverseGamma</span><span class="x">(</span><span class="mi">2</span><span class="x">,</span><span class="mi">3</span><span class="x">)</span>
    <span class="n">m</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">x</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
    <span class="n">y</span> <span class="o">~</span> <span class="n">Normal</span><span class="x">(</span><span class="n">m</span><span class="x">,</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">s</span><span class="x">))</span>
<span class="k">end</span>

<span class="c"># Providing a custom variance-covariance matrix</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">sample</span><span class="x">(</span>
    <span class="n">gdemo</span><span class="x">(</span><span class="mf">1.5</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">),</span> 
    <span class="n">MH</span><span class="x">(</span>
        <span class="x">[</span><span class="mf">0.25</span> <span class="mf">0.05</span><span class="x">;</span> 
         <span class="mf">0.05</span> <span class="mf">0.50</span><span class="x">]</span>
    <span class="x">),</span> 
    <span class="mi">1_000</span>
<span class="x">)</span>
<span class="n">mean</span><span class="x">(</span><span class="n">chain</span><span class="x">)</span>
</code></pre></div></div>

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/inference/mh.jl#L12-L150" class="documenter-source">source</a><br /></p>

<h3 id="-turinginferencenuts--type"><a id="Turing.Inference.NUTS" href="#Turing.Inference.NUTS">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.Inference.NUTS</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">NUTS</span><span class="x">(</span><span class="n">n_adapts</span><span class="o">::</span><span class="kt">Int</span><span class="x">,</span> <span class="n">δ</span><span class="o">::</span><span class="kt">Float64</span><span class="x">;</span> <span class="n">max_depth</span><span class="o">::</span><span class="kt">Int</span><span class="o">=</span><span class="mi">5</span><span class="x">,</span> <span class="n">Δ_max</span><span class="o">::</span><span class="kt">Float64</span><span class="o">=</span><span class="mf">1000.0</span><span class="x">,</span> <span class="n">ϵ</span><span class="o">::</span><span class="kt">Float64</span><span class="o">=</span><span class="mf">0.0</span><span class="x">)</span>
</code></pre></div></div>

<p>No-U-Turn Sampler (NUTS) sampler.</p>

<p>Usage:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">NUTS</span><span class="x">()</span>            <span class="c"># Use default NUTS configuration. </span>
<span class="n">NUTS</span><span class="x">(</span><span class="mi">1000</span><span class="x">,</span> <span class="mf">0.65</span><span class="x">)</span>  <span class="c"># Use 1000 adaption steps, and target accept ratio 0.65.</span>
</code></pre></div></div>

<p>Arguments:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">n_adapts::Int</code> : The number of samples to use with adaptation.</li>
  <li><code class="language-plaintext highlighter-rouge">δ::Float64</code> : Target acceptance rate for dual averaging.</li>
  <li><code class="language-plaintext highlighter-rouge">max_depth::Int</code> : Maximum doubling tree depth.</li>
  <li><code class="language-plaintext highlighter-rouge">Δ_max::Float64</code> : Maximum divergence during doubling tree.</li>
  <li><code class="language-plaintext highlighter-rouge">ϵ::Float64</code> : Inital step size; 0 means automatically searching using a heuristic procedure.</li>
</ul>

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/inference/hmc.jl#L284-L304" class="documenter-source">source</a><br /></p>

<h3 id="-turinginferencepg--type"><a id="Turing.Inference.PG" href="#Turing.Inference.PG">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.Inference.PG</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span><span class="nc"> PG</span><span class="x">{</span><span class="n">space</span><span class="x">,</span> <span class="n">R</span><span class="x">}</span> <span class="o">&lt;:</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Inference</span><span class="o">.</span><span class="n">ParticleInference</span>
</code></pre></div></div>

<p>Particle Gibbs sampler.</p>

<p>Note that this method is particle-based, and arrays of variables must be stored in a <a href="/v0.14/docs/library/#Libtask.TArray"><code class="language-plaintext highlighter-rouge">TArray</code></a> object.</p>

<p><strong>Fields</strong></p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">nparticles::Int64</code></p>

    <p>Number of particles.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">resampler::Any</code></p>

    <p>Resampling algorithm.</p>
  </li>
</ul>

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/inference/AdvancedSMC.jl#L154" class="documenter-source">source</a><br /></p>

<h3 id="-turinginferencesmc--type"><a id="Turing.Inference.SMC" href="#Turing.Inference.SMC">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.Inference.SMC</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span><span class="nc"> SMC</span><span class="x">{</span><span class="n">space</span><span class="x">,</span> <span class="n">R</span><span class="x">}</span> <span class="o">&lt;:</span> <span class="n">Turing</span><span class="o">.</span><span class="n">Inference</span><span class="o">.</span><span class="n">ParticleInference</span>
</code></pre></div></div>

<p>Sequential Monte Carlo sampler.</p>

<p><strong>Fields</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">resampler::Any</code></li>
</ul>

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/inference/AdvancedSMC.jl#L35" class="documenter-source">source</a><br /></p>

<p><a id="Distributions"></a></p>

<p><a id="Distributions-1"></a></p>

<h2 id="distributions">Distributions</h2>

<h3 id="-turingflat--type"><a id="Turing.Flat" href="#Turing.Flat">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.Flat</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Flat</span><span class="x">()</span>
</code></pre></div></div>

<p>The <em>flat distribution</em> is the improper distribution of real numbers that has the improper probability density function</p>

\[f(x) = 1.\]

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/stdlib/distributions.jl#L1-L10" class="documenter-source">source</a><br /></p>

<h3 id="-turingflatpos--type"><a id="Turing.FlatPos" href="#Turing.FlatPos">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.FlatPos</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">FlatPos</span><span class="x">(</span><span class="n">l</span><span class="o">::</span><span class="kt">Real</span><span class="x">)</span>
</code></pre></div></div>

<p>The <em>positive flat distribution</em> with real-valued parameter <code class="language-plaintext highlighter-rouge">l</code> is the improper distribution of real numbers that has the improper probability density function</p>

\[f(x) = \begin{cases}
0 &amp; \text{if } x \leq l, \\
1 &amp; \text{otherwise}.
\end{cases}\]

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/stdlib/distributions.jl#L26-L38" class="documenter-source">source</a><br /></p>

<h3 id="-turingbinomiallogit--type"><a id="Turing.BinomialLogit" href="#Turing.BinomialLogit">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.BinomialLogit</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BinomialLogit</span><span class="x">(</span><span class="n">n</span><span class="x">,</span> <span class="n">logitp</span><span class="x">)</span>
</code></pre></div></div>

<p>The <em>Binomial distribution</em> with logit parameterization characterizes the number of successes in a sequence of independent trials.</p>

<p>It has two parameters: <code class="language-plaintext highlighter-rouge">n</code>, the number of trials, and <code class="language-plaintext highlighter-rouge">logitp</code>, the logit of the probability of success in an individual trial, with the distribution</p>

\[P(X = k) = {n \choose k}{(\text{logistic}(logitp))}^k (1 - \text{logistic}(logitp))^{n-k}, \quad \text{ for } k = 0,1,2, \ldots, n.\]

<p>See also: <a href="@ref"><code class="language-plaintext highlighter-rouge">Binomial</code></a></p>

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/stdlib/distributions.jl#L62-L76" class="documenter-source">source</a><br /></p>

<p>!!! warning “Missing docstring.”
    Missing docstring for <code class="language-plaintext highlighter-rouge">VecBinomialLogit</code>. Check Documenter’s build log for details.</p>

<h3 id="-turingorderedlogistic--type"><a id="Turing.OrderedLogistic" href="#Turing.OrderedLogistic">#</a> <strong><code class="language-plaintext highlighter-rouge">Turing.OrderedLogistic</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">OrderedLogistic</span><span class="x">(</span><span class="n">η</span><span class="x">,</span> <span class="n">c</span><span class="o">::</span><span class="kt">AbstractVector</span><span class="x">)</span>
</code></pre></div></div>

<p>The <em>ordered logistic distribution</em> with real-valued parameter <code class="language-plaintext highlighter-rouge">η</code> and cutpoints <code class="language-plaintext highlighter-rouge">c</code> has the probability mass function</p>

\[P(X = k) = \begin{cases}
    1 - \text{logistic}(\eta - c_1) &amp; \text{if } k = 1, \\
    \text{logistic}(\eta - c_{k-1}) - \text{logistic}(\eta - c_k) &amp; \text{if } 1 &lt; k &lt; K, \\
    \text{logistic}(\eta - c_{K-1}) &amp; \text{if } k = K,
\end{cases}\]

<p>where <code class="language-plaintext highlighter-rouge">K = length(c) + 1</code>.</p>

<p><a target="_blank" href="https://github.com/TuringLang/Turing.jl/blob/717909e09038329e61f382badd8700072960ec98/src/stdlib/distributions.jl#L119-L133" class="documenter-source">source</a><br /></p>

<p><a id="Data-Structures"></a></p>

<p><a id="Data-Structures-1"></a></p>

<h2 id="data-structures">Data Structures</h2>

<h3 id="-libtasktarray--type"><a id="Libtask.TArray" href="#Libtask.TArray">#</a> <strong><code class="language-plaintext highlighter-rouge">Libtask.TArray</code></strong> — <em>Type</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">TArray</span><span class="x">{</span><span class="n">T</span><span class="x">}(</span><span class="n">dims</span><span class="x">,</span> <span class="o">...</span><span class="x">)</span>
</code></pre></div></div>

<p>Implementation of data structures that automatically perform copy-on-write after task copying.</p>

<p>If current*task is an existing key in <code class="language-plaintext highlighter-rouge">s</code>, then return <code class="language-plaintext highlighter-rouge">s[current*task]</code>. Otherwise, return<code class="language-plaintext highlighter-rouge">s[current*task] = s[last*task]</code>.</p>

<p>Usage:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">TArray</span><span class="x">(</span><span class="n">dim</span><span class="x">)</span>
</code></pre></div></div>

<p>Example:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ta</span> <span class="o">=</span> <span class="n">TArray</span><span class="x">(</span><span class="mi">4</span><span class="x">)</span>              <span class="c"># init</span>
<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="o">:</span><span class="mi">4</span> <span class="n">ta</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">=</span> <span class="n">i</span> <span class="k">end</span>  <span class="c"># assign</span>
<span class="kt">Array</span><span class="x">(</span><span class="n">ta</span><span class="x">)</span>                   <span class="c"># convert to 4-element Array{Int64,1}: [1, 2, 3, 4]</span>
</code></pre></div></div>

<p><a id="Utilities"></a></p>

<p><a id="Utilities-1"></a></p>

<h2 id="utilities">Utilities</h2>

<h3 id="-libtasktzeros--function"><a id="Libtask.tzeros" href="#Libtask.tzeros">#</a> <strong><code class="language-plaintext highlighter-rouge">Libtask.tzeros</code></strong> — <em>Function</em>.</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">tzeros</span><span class="x">(</span><span class="n">dims</span><span class="x">,</span> <span class="o">...</span><span class="x">)</span>
</code></pre></div></div>

<p>Construct a distributed array of zeros. Trailing arguments are the same as those accepted by <code class="language-plaintext highlighter-rouge">TArray</code>.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tzeros</span><span class="x">(</span><span class="n">dim</span><span class="x">)</span>
</code></pre></div></div>

<p>Example:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tz</span> <span class="o">=</span> <span class="n">tzeros</span><span class="x">(</span><span class="mi">4</span><span class="x">)</span>              <span class="c"># construct</span>
<span class="kt">Array</span><span class="x">(</span><span class="n">tz</span><span class="x">)</span>                   <span class="c"># convert to 4-element Array{Int64,1}: [0, 0, 0, 0]</span>
</code></pre></div></div>

